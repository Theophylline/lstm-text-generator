{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikeq\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133526, 25, 112)\n",
      "(133526, 25, 112)\n",
      "input sequence: The preceding decades hav\n",
      "--------------\n",
      "output sequence: he preceding decades have\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "\n",
    "SEQ_LENGTH = 25\n",
    "\n",
    "# ISSUES\n",
    "# (1) use partially superimposed sequences as input data -> more training data\n",
    "# (2) need to change output size to (num_sequences, vocab_size)\n",
    "# (3) use separate text file for predictions; draw sample sequences from the test set\n",
    "# (4) for predictions, generate a new character with a given sequence, append the character, and remove the first character in that sequence\n",
    "# (5) add dropout layers\n",
    "\n",
    "# load sample text and build vocabulary\n",
    "with open('abstract_train.txt', encoding='utf-16') as data:\n",
    "    text = list(data.read())\n",
    "    chars = set(text)\n",
    "    VOCAB_SIZE = len(chars)\n",
    "    char_idx = {char:idx for idx, char in enumerate(chars)}\n",
    "    idx_char = {idx: char for idx, char in enumerate(chars)}\n",
    "    \n",
    "    # slice raw text into partially superimposed sequences\n",
    "    char_vec = []\n",
    "    for i, v in enumerate(text[:-SEQ_LENGTH]):\n",
    "        char_vec.append(text[i:i+SEQ_LENGTH]) # convert each character in text into one hot vec\n",
    "    \n",
    "    # convert each character in each sequence into index values in char_idx\n",
    "    for i, seq in enumerate(char_vec):\n",
    "        for j, c in enumerate(seq):\n",
    "            char_vec[i][j] = char_idx[c]\n",
    "            char_vec[i][j] = np_utils.to_categorical(char_vec[i][j], num_classes=VOCAB_SIZE)\n",
    "    \n",
    "\n",
    "input_seq = np.array(char_vec[0:-1])\n",
    "output_seq = np.array(char_vec[1:])\n",
    "\n",
    "\n",
    "# testing: see if input/output sequences are correct\n",
    "print(input_seq.shape)\n",
    "print(output_seq.shape)\n",
    "s = ''\n",
    "for i in range(SEQ_LENGTH):\n",
    "    idx = np.where(input_seq[0][i][:] == 1)\n",
    "    s += idx_char[idx[0][0]]\n",
    "print('input sequence:', s)\n",
    "\n",
    "print('--------------')\n",
    "s = ''\n",
    "for i in range(SEQ_LENGTH):\n",
    "    idx = np.where(output_seq[0][i][:] == 1)\n",
    "    s += idx_char[idx[0][0]]\n",
    "print('output sequence:', s)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 25, 256)           377856    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 25, 256)           525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 25, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 25, 112)           28784     \n",
      "=================================================================\n",
      "Total params: 931,952\n",
      "Trainable params: 931,952\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, TimeDistributed, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(SEQ_LENGTH, VOCAB_SIZE), return_sequences=True)) # input_shape = (SEQ_LENGTH, VOCAB_SIZE)\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(TimeDistributed(Dense(VOCAB_SIZE, activation='softmax')))\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "133526/133526 [==============================] - 419s 3ms/step - loss: 2.0623\n",
      "Epoch 2/25\n",
      "133526/133526 [==============================] - 421s 3ms/step - loss: 1.4325\n",
      "Epoch 3/25\n",
      "133526/133526 [==============================] - 421s 3ms/step - loss: 1.2362\n",
      "Epoch 4/25\n",
      "133526/133526 [==============================] - 425s 3ms/step - loss: 1.1242 1s - l - ETA: 0s - loss: 1.124\n",
      "Epoch 5/25\n",
      "133526/133526 [==============================] - 424s 3ms/step - loss: 1.0475 1s \n",
      "Epoch 6/25\n",
      "133526/133526 [==============================] - 422s 3ms/step - loss: 0.9913\n",
      "Epoch 7/25\n",
      "133526/133526 [==============================] - 430s 3ms/step - loss: 0.9485\n",
      "Epoch 8/25\n",
      "133526/133526 [==============================] - 425s 3ms/step - loss: 0.9139 \n",
      "Epoch 9/25\n",
      "133526/133526 [==============================] - 427s 3ms/step - loss: 0.8870\n",
      "Epoch 10/25\n",
      "133526/133526 [==============================] - 425s 3ms/step - loss: 0.8632\n",
      "Epoch 11/25\n",
      "133526/133526 [==============================] - 424s 3ms/step - loss: 0.8447\n",
      "Epoch 12/25\n",
      "133526/133526 [==============================] - 422s 3ms/step - loss: 0.8274\n",
      "Epoch 13/25\n",
      "133526/133526 [==============================] - 417s 3ms/step - loss: 0.8132\n",
      "Epoch 14/25\n",
      "133526/133526 [==============================] - 417s 3ms/step - loss: 0.8005\n",
      "Epoch 15/25\n",
      "133526/133526 [==============================] - 416s 3ms/step - loss: 0.7884\n",
      "Epoch 16/25\n",
      "133526/133526 [==============================] - 417s 3ms/step - loss: 0.7786\n",
      "Epoch 17/25\n",
      "133526/133526 [==============================] - 417s 3ms/step - loss: 0.7696\n",
      "Epoch 18/25\n",
      "133526/133526 [==============================] - 425s 3ms/step - loss: 0.7610\n",
      "Epoch 19/25\n",
      "133526/133526 [==============================] - 426s 3ms/step - loss: 0.7535\n",
      "Epoch 20/25\n",
      "133526/133526 [==============================] - 425s 3ms/step - loss: 0.7455\n",
      "Epoch 21/25\n",
      "133526/133526 [==============================] - 427s 3ms/step - loss: 0.7392 0s - loss: 0\n",
      "Epoch 22/25\n",
      "133526/133526 [==============================] - 417s 3ms/step - loss: 0.7333\n",
      "Epoch 23/25\n",
      "133526/133526 [==============================] - 419s 3ms/step - loss: 0.7271\n",
      "Epoch 24/25\n",
      "133526/133526 [==============================] - 419s 3ms/step - loss: 0.7216\n",
      "Epoch 25/25\n",
      "133526/133526 [==============================] - 418s 3ms/step - loss: 0.7174\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# train model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam')\n",
    "model.fit(x=input_seq, y=output_seq, batch_size=32, epochs=25) # shuffle = False if stateful = Tru\n",
    "model.save_weights('lstm_weights.h5')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed text: red in full however, the \n",
      "-----------\n",
      "predicted text: physical characterisation of the porphyrin changes to a nanomedicine platform early in development of artificial phospholipid bilayer membrane and induce a toxic immune response (73). Antibody fragments, such as sodium cholate (137). They are able to detect solid tumors for PDT therapy (PDT) is a th\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "from random import randint\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def generate_text(model, length):\n",
    "    with open('abstract_test.txt') as data:\n",
    "        text = list(data.read())\n",
    "        \n",
    "    predicted_text = []\n",
    "    idx = randint(0, len(text)-SEQ_LENGTH)\n",
    "    tmp = text[idx:idx+SEQ_LENGTH] # sample seed sequence from raw text\n",
    "    \n",
    "    # one hot encoding of seed text\n",
    "    x_test = np.zeros((SEQ_LENGTH, VOCAB_SIZE))\n",
    "    for i, c in enumerate(tmp):\n",
    "        x_test[i] = np_utils.to_categorical(char_idx[c], num_classes=VOCAB_SIZE)\n",
    "    x_test = np.reshape(x_test, (1, SEQ_LENGTH, VOCAB_SIZE))\n",
    "    \n",
    "    # model predictions\n",
    "    for i in range(length):\n",
    "        probabilities = model.predict(x_test)\n",
    "        k = np.argmax(probabilities, axis=2)[0]\n",
    "        new_char = np_utils.to_categorical(k[-1], num_classes=VOCAB_SIZE)\n",
    "        new_char = np.reshape(new_char, (1, 1, VOCAB_SIZE))\n",
    "        x_test = np.append(x_test, new_char, axis=1)\n",
    "        x_test = x_test[:, 1:, :]\n",
    "        predicted_text.append(idx_char[k[-1]])\n",
    "\n",
    "    \n",
    "    print('Seed text:', ''.join(tmp))\n",
    "    print('-----------')\n",
    "    print('predicted text:', ''.join(predicted_text))\n",
    "        \n",
    "    # convert one hot vectors to string\n",
    "generate_text(model, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
